{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
    "documents = dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples = 2500\n",
    "n_features = 1000\n",
    "n_components = 10\n",
    "n_top_words = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_documents = documents[:n_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# max_df - sets threshold for words that are filtered out according to their frequency of appearance in the documents\n",
    "#          with 1.0 corresponding to appearance in all docs\n",
    "vectorizer = CountVectorizer(max_df=0.95, min_df = 2, max_features=n_features, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_vectors = vectorizer.fit_transform(random_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 1000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'usenet', 934),\n",
       " (u'want', 951),\n",
       " (u'wrong', 989),\n",
       " (u'fit', 369),\n",
       " (u'service', 811),\n",
       " (u'needed', 622),\n",
       " (u'saying', 787),\n",
       " (u'lots', 549),\n",
       " (u'nature', 619),\n",
       " (u'dave', 266),\n",
       " (u'begin', 138),\n",
       " (u'os2', 659),\n",
       " (u'choice', 200),\n",
       " (u'ground', 410),\n",
       " (u'address', 78),\n",
       " (u'working', 981),\n",
       " (u'following', 374),\n",
       " (u'years', 996),\n",
       " (u'didn', 286),\n",
       " (u'seriously', 809),\n",
       " (u'internet', 477),\n",
       " (u'types', 922),\n",
       " (u'turned', 919),\n",
       " (u'printer', 708),\n",
       " (u'wants', 953)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(key, vectorizer.vocabulary_[key]) for key in vectorizer.vocabulary_.keys()[:25]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=n_components, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda = lda.fit(doc_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda_allocation = lda.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1000)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_allocation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "allocations = pd.DataFrame(lda_allocation.T, index=vectorizer.vocabulary_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0  worked      0    211.727966\n",
       "   excellent   0    192.410831\n",
       "   follow      0    165.539641\n",
       "   added       0    161.833748\n",
       "   claim       0    151.827698\n",
       "   completely  0    146.279304\n",
       "   medical     0    135.931053\n",
       "   went        0    127.027810\n",
       "   heads       0    124.866495\n",
       "   ones        0    114.008946\n",
       "1  heads       1    629.161479\n",
       "   follow      1    564.071298\n",
       "   money       1    509.455978\n",
       "   added       1    440.065241\n",
       "   went        1    431.489990\n",
       "   worked      1    430.308725\n",
       "   just        1    309.023552\n",
       "   political   1    305.457884\n",
       "   earth       1    272.837920\n",
       "   copies      1    265.157250\n",
       "2  wrong       2    345.237320\n",
       "   video       2    204.642010\n",
       "   books       2    186.736562\n",
       "   service     2    180.904424\n",
       "   didn        2    171.701434\n",
       "   sell        2    158.369609\n",
       "   paul        2    154.681324\n",
       "   usenet      2    142.233546\n",
       "   allowed     2    138.491948\n",
       "   dave        2    137.395122\n",
       "3  31          3    132.353373\n",
       "   rate        3    112.980009\n",
       "   clearly     3    108.753461\n",
       "   shall       3     95.668264\n",
       "   reference   3     93.236169\n",
       "   old         3     80.628091\n",
       "   sun         3     79.029040\n",
       "   limited     3     78.270105\n",
       "   looks       3     57.869753\n",
       "   david       3     54.935950\n",
       "4  let         4    425.705985\n",
       "   happy       4    228.892820\n",
       "   story       4    199.658761\n",
       "   usenet      4    193.907214\n",
       "   entire      4    171.630791\n",
       "   sounds      4    119.341661\n",
       "   nice        4    105.422272\n",
       "   life        4    103.526547\n",
       "   11          4    102.911435\n",
       "   80          4     99.745695\n",
       "5  rights      5    409.982091\n",
       "   try         5    141.722691\n",
       "   ok          5    127.767619\n",
       "   words       5    119.137755\n",
       "   looks       5    104.497460\n",
       "   message     5    102.685036\n",
       "   money       5    101.649764\n",
       "   cards       5     92.742219\n",
       "   later       5     90.792592\n",
       "   california  5     81.789969\n",
       "dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allocations.stack().groupby(level=1).nlargest(10).loc[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5  rights        5    409.982091\n",
       "   try           5    141.722691\n",
       "   ok            5    127.767619\n",
       "   words         5    119.137755\n",
       "   looks         5    104.497460\n",
       "   message       5    102.685036\n",
       "   money         5    101.649764\n",
       "   cards         5     92.742219\n",
       "   later         5     90.792592\n",
       "   california    5     81.789969\n",
       "6  let           6    270.039255\n",
       "   set           6    242.852168\n",
       "   read          6    237.013240\n",
       "   22            6    236.553809\n",
       "   rates         6    220.494282\n",
       "   required      6    202.911669\n",
       "   great         6    193.660760\n",
       "   states        6    192.185932\n",
       "   sorry         6    186.992189\n",
       "   received      6    178.120694\n",
       "7  view          7    148.878403\n",
       "   ones          7    126.892980\n",
       "   ac            7    122.847683\n",
       "   84            7    122.740312\n",
       "   money         7    110.088729\n",
       "   paul          7    102.990334\n",
       "   agree         7     86.450001\n",
       "   certainly     7     73.609572\n",
       "   human         7     71.618176\n",
       "   lk            7     68.376092\n",
       "8  rate          8     81.686785\n",
       "   seen          8     76.461370\n",
       "   goes          8     72.882819\n",
       "   bob           8     68.767820\n",
       "   word          8     57.794177\n",
       "   giving        8     43.637235\n",
       "   specifically  8     39.538639\n",
       "   live          8     34.848312\n",
       "   design        8     33.141462\n",
       "   regular       8     32.843043\n",
       "9  history       9    268.905582\n",
       "   3d            9    164.762409\n",
       "   money         9    158.131133\n",
       "   reference     9    145.550807\n",
       "   crime         9    127.263507\n",
       "   break         9    122.731242\n",
       "   limited       9    108.817272\n",
       "   looks         9    107.705764\n",
       "   assume        9    104.413139\n",
       "   got           9     99.836572\n",
       "dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allocations.stack().groupby(level=1).nlargest(10).loc[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:topic-modeling]",
   "language": "python",
   "name": "conda-env-topic-modeling-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
